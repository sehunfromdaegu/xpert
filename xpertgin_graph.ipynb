{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shunhun33/anaconda3/envs/xperttest/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No TPUs...\n",
      "Dataset: PROTEINS, Model: xpert, Patch Size: 5, Embed Dim: 192, Depth: 5\n",
      "Dataset PROTEINS already exists! Skipping: dataset will not be created.\n",
      "PROTEINS labels: [0 1]\n",
      "Graph labels are the same as the labels in the persistence diagram dataset: True\n",
      "Starting Fold 1/10\n",
      "Fold 1/10 - Best Test Accuracy: 0.714\n",
      "Starting Fold 2/10\n",
      "Fold 2/10 - Best Test Accuracy: 0.723\n",
      "Starting Fold 3/10\n",
      "Fold 3/10 - Best Test Accuracy: 0.777\n",
      "Starting Fold 4/10\n",
      "Fold 4/10 - Best Test Accuracy: 0.757\n",
      "Starting Fold 5/10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "\n",
    "from utils import convert_to_epd_list, rotate_epds, pixelization, train_one_epoch, test\n",
    "from load_models import load_model\n",
    "from gdeep.data.datasets.persistence_diagrams_from_graphs_builder import PersistenceDiagramFromGraphBuilder\n",
    "from gdeep.data.datasets import PersistenceDiagramFromFiles\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters and configurations\n",
    "dataname = 'PROTEINS' # Choose from ['IMDB-BINARY', 'IMDB-MULTI', 'MUTAG', 'PROTEINS', 'COX2', 'DHFR'] \n",
    "model_name = 'xpert'  # Choose from ['xpert', 'gin', 'gin_assisted_concat', 'gin_assisted_sum']\n",
    "grid_size = 50\n",
    "patch_size = 5\n",
    "embed_dim = 192\n",
    "depth = 5\n",
    "epochs = 300\n",
    "lr = 0.001\n",
    "warmup_t = 50\n",
    "batch_size = 64\n",
    "n_splits = 10\n",
    "patience = 100\n",
    "min_epochs = 30\n",
    "\n",
    "print(f\"Dataset: {dataname}, Model: {model_name}, Patch Size: {patch_size}, Embed Dim: {embed_dim}, Depth: {depth}\")\n",
    "\n",
    "def labels_preprocess(labels):\n",
    "    \"\"\"Preprocess labels based on dataset name.\"\"\"\n",
    "    if dataname in ['IMDB-MULTI', 'PROTEINS']:\n",
    "        labels = labels - 1\n",
    "    if any(name in dataname for name in ['MUTAG', 'COX2', 'DHFR']):\n",
    "        labels = 0.5 * labels + 0.5    \n",
    "    return labels\n",
    "\n",
    "# Load the dataset\n",
    "dataset = TUDataset(root='./data/GraphDatasets/', name=dataname)\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "# Initialize tensor for pixelized persistence diagrams\n",
    "ppd = torch.zeros((len(dataset), 4, grid_size, grid_size), dtype=torch.float32)\n",
    "\n",
    "# Create persistence diagrams from graphs\n",
    "diffusion_parameter = 1.0\n",
    "pd_creator = PersistenceDiagramFromGraphBuilder(dataname, diffusion_parameter=diffusion_parameter, root='./data')\n",
    "pd_creator.create()\n",
    "\n",
    "# Load persistence diagrams\n",
    "pd_ds = PersistenceDiagramFromFiles(\n",
    "    os.path.join('./data', f\"{dataname}_{diffusion_parameter}_extended_persistence\")\n",
    ")\n",
    "\n",
    "# Preprocess labels\n",
    "labels = [pd_ds[i][1] for i in range(len(pd_ds))]\n",
    "labels = np.array(labels)\n",
    "labels = labels_preprocess(labels)\n",
    "print(f'{dataname} labels: {np.unique(labels)}')\n",
    "\n",
    "# Convert and rotate persistence diagrams\n",
    "epds, _ = convert_to_epd_list(pd_ds)\n",
    "repds = rotate_epds(epds)  # List of rotated persistence diagrams\n",
    "\n",
    "# Pixelize persistence diagrams\n",
    "for i in range(len(repds)):\n",
    "    ppd[i] = pixelization(repds[i], grid_size=grid_size, device='cpu')\n",
    "\n",
    "# Verify that graph labels match persistence diagram labels\n",
    "graph_labels = [dataset[i].y.item() for i in range(len(dataset))]\n",
    "num_same_labels = (np.array(graph_labels) == labels).sum()\n",
    "sanity = (num_same_labels == len(dataset))\n",
    "print(f\"Graph labels are the same as the labels in the persistence diagram dataset: {sanity}\")\n",
    "\n",
    "if not sanity:\n",
    "    print(\"Warning: Graph labels do not match persistence diagram labels.\")\n",
    "\n",
    "# Prepare data list\n",
    "data_list = []\n",
    "for idx, data in enumerate(dataset):\n",
    "    data.node_feat = torch.ones((data.num_nodes, 1), dtype=torch.float32)\n",
    "    data.ppd = ppd[idx]  # ppd[i].shape = (4, grid_size, grid_size)\n",
    "    data_list.append(data)\n",
    "\n",
    "# Stratified K-Fold cross-validation\n",
    "skfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "best_test_acc_list = []\n",
    "\n",
    "# Cross-validation loop\n",
    "for fold, (train_idx, test_idx) in enumerate(skfold.split(data_list, labels)):\n",
    "    print(f\"Starting Fold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    # Load model\n",
    "    model = load_model(\n",
    "        model_name, device, num_classes, grid_size, patch_size,\n",
    "        depth=depth, embed_dim=embed_dim\n",
    "    )\n",
    "    \n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(Subset(data_list, train_idx), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(Subset(data_list, test_idx), batch_size=batch_size)\n",
    "    \n",
    "    # Optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = CosineLRScheduler(\n",
    "        optimizer,\n",
    "        t_initial=epochs,\n",
    "        cycle_mul=1,\n",
    "        lr_min=0.05 * lr,\n",
    "        cycle_decay=1.0,\n",
    "        warmup_lr_init=0.05 * lr,\n",
    "        warmup_t=warmup_t,\n",
    "        cycle_limit=1,\n",
    "        t_in_epochs=True\n",
    "    )\n",
    "    \n",
    "    best_test_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    epochs_no_improve = 0  # Counter for epochs with no improvement\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device, scheduler = scheduler)\n",
    "        \n",
    "        # Validation\n",
    "        test_loss, test_acc = test(model, test_loader, criterion, device)\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            best_epoch = epoch\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1  \n",
    "    \n",
    "    print(f'Fold {fold + 1}/{n_splits} - Best Test Accuracy: {best_test_acc:.3f}')\n",
    "    best_test_acc_list.append(best_test_acc)\n",
    "\n",
    "# Final results\n",
    "avg_acc = np.mean(best_test_acc_list)\n",
    "std_acc = np.std(best_test_acc_list)\n",
    "print(f'Average Best Test Accuracy over {n_splits} folds: {avg_acc:.3f} Â± {std_acc:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xperttest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
