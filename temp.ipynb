{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No TPUs...\n"
     ]
    }
   ],
   "source": [
    "from gdeep.data.datasets import OrbitsGenerator, create_pd_orbits\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "og = OrbitsGenerator(parameters = (2.5, 3.5, 4.0, 4.1, 4.3), \n",
    "                     num_orbits_per_class = 1000, \n",
    "                     num_pts_per_orbit = 1000, \n",
    "                     homology_dimensions = (0, 1), \n",
    "                     validation_percentage = 0.0, \n",
    "                     test_percentage = 0.0, \n",
    "                     dynamical_system = 'classical_convention', \n",
    "                     n_jobs = 1, \n",
    "                     dtype = 'float32', \n",
    "                     arbitrary_precision=False)\n",
    "\n",
    "og.get_orbits()\n",
    "labels = og._labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Include necessary general imports\n",
    "import os\n",
    "from typing import Tuple\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "# Torch imports\n",
    "from orbit_utils import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Gdeep imports \n",
    "\n",
    "from gdeep.data.datasets import OrbitsGenerator\n",
    "import numpy as np\n",
    "\n",
    "patience = 50\n",
    "samples_per_class = 1000\n",
    "num_repeat = 5\n",
    "patch_size = 5\n",
    "embed_dim = 192\n",
    "depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth: 5, embed_dim: 192 patch_size: 5, samples_per_class: 1000\n",
      "Epoch 2 Accuracy: 69.87(best: 69.87 at 2), time: 3.291"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "best_test_accs = []\n",
    "print(f'depth: {depth}, embed_dim: {embed_dim} patch_size: {patch_size}, samples_per_class: {samples_per_class}')\n",
    "for i in range(num_repeat):\n",
    "    model_name = 'xpert'\n",
    "\n",
    "    config = {\n",
    "        'bs': 64,\n",
    "        'embed_dim': embed_dim,\n",
    "        'depth': depth,\n",
    "        'num_heads': 8,\n",
    "        'grid_size': 50,\n",
    "        'patch_size': patch_size,\n",
    "    }\n",
    "\n",
    "    hyper_config = {\n",
    "        'epochs': 300,\n",
    "        'lr': 0.0001,\n",
    "        'warmup_t': 50,\n",
    "    }\n",
    "\n",
    "    # Generate a configuration file with the parameters of the desired dataset\n",
    "    @dataclass\n",
    "    class Orbit5kConfig():\n",
    "        batch_size_train: int = 8\n",
    "        num_orbits_per_class: int = samples_per_class\n",
    "        validation_percentage: float = 0.\n",
    "        test_percentage: float = 0.3\n",
    "        num_jobs: int = 8\n",
    "        dynamical_system: str = \"classical_convention\"\n",
    "        homology_dimensions: Tuple[int, int] = (0, 1)  # type: ignore\n",
    "        dtype: str = \"float32\"\n",
    "        arbitrary_precision: bool = False\n",
    "\n",
    "    config_data = Orbit5kConfig()\n",
    "    valid_dgms = False\n",
    "\n",
    "\n",
    "    while not valid_dgms:\n",
    "        og = OrbitsGenerator(\n",
    "            num_orbits_per_class=config_data.num_orbits_per_class,\n",
    "            homology_dimensions=config_data.homology_dimensions,\n",
    "            validation_percentage=config_data.validation_percentage,\n",
    "            test_percentage=config_data.test_percentage,\n",
    "            n_jobs=config_data.num_jobs,\n",
    "            dynamical_system=config_data.dynamical_system,\n",
    "            dtype=config_data.dtype,\n",
    "        )\n",
    "            \n",
    "        giotto_pdg = og.get_persistence_diagrams()\n",
    "        labels = og._labels\n",
    "        dgms, labels = pdg_dataset(giotto_pdg, labels, model_name=model_name)\n",
    "\n",
    "        dgms0 = dgms[0].reshape(-1)\n",
    "        dgms1 = dgms[1].reshape(-1)\n",
    "        \n",
    "        valid_test0 = ((dgms0 < 0).sum() == 0)\n",
    "        valid_test1 = ((dgms0 > 1).sum() == 0)\n",
    "        valid_test2 = ((dgms1 < 0).sum() == 0)\n",
    "        valid_test3 = ((dgms1 > 1).sum() == 0)\n",
    "        valid_dgms = valid_test0 and valid_test1 and valid_test2 and valid_test3\n",
    "\n",
    "\n",
    "    train_indices, test_indices = train_test_split(np.arange(len(labels)), test_size=0.3)\n",
    "\n",
    "    if model_name == 'xpert':\n",
    "        dgms0, dgms1 = dgms\n",
    "\n",
    "        dgms0_train, dgms1_train, labels_train = dgms0[train_indices], dgms1[train_indices], labels[train_indices]\n",
    "        dgms0_test, dgms1_test, labels_test = dgms0[test_indices], dgms1[test_indices], labels[test_indices]\n",
    "\n",
    "        train_dataset = TensorDataset(dgms0_train, dgms1_train, labels_train)\n",
    "        test_dataset = TensorDataset(dgms0_test, dgms1_test, labels_test)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=config['bs'], shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    elif model_name == 'persformer':\n",
    "\n",
    "        masks = generate_masks(giotto_pdg)\n",
    "        giotto_pdg = torch.tensor(giotto_pdg, dtype=torch.float32)\n",
    "        masks = torch.tensor(masks, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        train_dataset = TensorDataset(giotto_pdg[train_indices], masks[train_indices], labels[train_indices])\n",
    "        test_dataset = TensorDataset(giotto_pdg[test_indices], masks[test_indices], labels[test_indices])\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=config['bs'], shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "        \n",
    "    from load_models import load_model_orbit\n",
    "    from timm.scheduler import CosineLRScheduler\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = load_model_orbit(model_name, config).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=hyper_config['lr'])\n",
    "    scheduler = CosineLRScheduler(\n",
    "                optimizer,\n",
    "                t_initial=hyper_config['epochs'],\n",
    "                cycle_mul=1,\n",
    "                lr_min=0.05*hyper_config['lr'],\n",
    "                cycle_decay=1.,\n",
    "                warmup_lr_init=0.05*hyper_config['lr'],\n",
    "                warmup_t=hyper_config['warmup_t'],\n",
    "                cycle_limit=1,\n",
    "                t_in_epochs=True\n",
    "            )\n",
    "\n",
    "    best_test_acc = 0\n",
    "    for epoch in range(hyper_config['epochs']):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if model_name == 'persformer':\n",
    "                dgms, mask, labels = data\n",
    "                dgms, mask, labels = dgms.to(device), mask.to(device), labels.to(device)\n",
    "                output = model(dgms, mask)\n",
    "\n",
    "            elif model_name == 'xpert':\n",
    "                dgms0, dgms1, labels = data\n",
    "                dgms0, dgms1, labels = dgms0.to(device), dgms1.to(device), labels.to(device)\n",
    "                output = model(dgms0, dgms1)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step(epoch)\n",
    "        \n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data in test_loader:\n",
    "                if model_name == 'persformer':\n",
    "                    dgms, mask, labels = data\n",
    "                    dgms, mask, labels = dgms.to(device), mask.to(device), labels.to(device)\n",
    "                    output = model(dgms, mask)\n",
    "\n",
    "                elif model_name == 'xpert':\n",
    "                    dgms0, dgms1, labels = data\n",
    "                    dgms0, dgms1, labels = dgms0.to(device), dgms1.to(device), labels.to(device)\n",
    "                    output = model(dgms0, dgms1)\n",
    "\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            test_acc = 100 * correct / total\n",
    "            if test_acc > best_test_acc:\n",
    "                best_test_acc = test_acc\n",
    "                best_epoch = epoch\n",
    "\n",
    "            end_time = time.time()\n",
    "            print(f'\\rEpoch {epoch} Accuracy: {test_acc:.2f}(best: {best_test_acc:.2f} at {best_epoch}), time: {(end_time - start_time):.3f}', end='')\n",
    "\n",
    "        if epoch - best_epoch > patience:\n",
    "            break\n",
    "    print()\n",
    "    best_test_accs.append(best_test_acc)\n",
    "print(f'mean test accuracy: {np.mean(best_test_accs)} +- {np.std(best_test_accs)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "dataname = 'MUTAG'\n",
    "dataset = TUDataset(root=f'./data/GraphDatasets/{dataname}', name=dataname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xpert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
